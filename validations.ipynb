{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "439c7106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffd4b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52c76426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    api_key=api_key,\n",
    "    model=\"claude-3-5-haiku-latest\",  # or \"claude-3-5-haiku-20241022\"\n",
    "    temperature=0.0,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "# response = llm.invoke(\"What is LangChain?\")\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c54dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a software development expert, training some absolute beginner students.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a software development expert, training some absolute beginner students.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eb00a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a software development expert, training some absolute beginner students.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatAnthropic(model='claude-3-5-haiku-latest', temperature=0.0, anthropic_api_url='https://api.anthropic.com', anthropic_api_key=SecretStr('**********'), model_kwargs={})\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f304ff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source Python library designed to help developers build applications using large language models (LLMs) like GPT-3, GPT-4, or Claude. Here's a comprehensive overview:\n",
      "\n",
      "Key Features:\n",
      "1. Modular Components\n",
      "- Provides building blocks for creating AI-powered applications\n",
      "- Simplifies interaction with language models\n",
      "- Supports multiple AI providers (OpenAI, Anthropic, Hugging Face, etc.)\n",
      "\n",
      "Main Capabilities:\n",
      "- Prompt management\n",
      "- Chain creation (sequences of AI interactions)\n",
      "- Memory management\n",
      "- Data retrieval and integration\n",
      "- Agent-based reasoning\n",
      "- Tool integration\n",
      "\n",
      "Common Use Cases:\n",
      "- Chatbots\n",
      "- Question-answering systems\n",
      "- Document analysis\n",
      "- Summarization tools\n",
      "- Code generation assistants\n",
      "- Research and data exploration tools\n",
      "\n",
      "Example Workflow:\n",
      "```python\n",
      "from langchain.llms import OpenAI\n",
      "from langchain.prompts import PromptTemplate\n",
      "\n",
      "# Create language model\n",
      "llm = OpenAI(temperature=0.7)\n",
      "\n",
      "# Define prompt template\n",
      "prompt = PromptTemplate(\n",
      "    input_variables=[\"topic\"],\n",
      "    template=\"Explain {topic} in simple terms\"\n",
      ")\n",
      "\n",
      "# Create chain\n",
      "chain = prompt | llm\n",
      "result = chain.invoke({\"topic\": \"quantum computing\"})\n",
      "```\n",
      "\n",
      "Key Advantages:\n",
      "- Abstracts complex LLM interactions\n",
      "- Flexible and extensible\n",
      "- Supports complex AI workflows\n",
      "- Open-source and actively developed\n"
     ]
    }
   ],
   "source": [
    "chain_result = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "print(chain_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d28e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source Python library designed to help developers build applications using large language models (LLMs) like GPT-3, GPT-4, or Claude. Here's a comprehensive overview:\n",
      "\n",
      "Key Features:\n",
      "1. Modular Components\n",
      "- Provides building blocks for creating AI-powered applications\n",
      "- Simplifies interaction with language models\n",
      "- Supports multiple AI providers (OpenAI, Anthropic, Hugging Face, etc.)\n",
      "\n",
      "Main Capabilities:\n",
      "- Prompt management\n",
      "- Chain creation (sequences of AI interactions)\n",
      "- Memory management\n",
      "- Data retrieval and integration\n",
      "- Agent-based reasoning\n",
      "- Tool integration\n",
      "\n",
      "Common Use Cases:\n",
      "- Chatbots\n",
      "- Question-answering systems\n",
      "- Document analysis\n",
      "- Summarization tools\n",
      "- Code generation assistants\n",
      "- Research and data exploration tools\n",
      "\n",
      "Example Workflow:\n",
      "```python\n",
      "from langchain.llms import OpenAI\n",
      "from langchain.prompts import PromptTemplate\n",
      "\n",
      "# Create language model\n",
      "llm = OpenAI(temperature=0.7)\n",
      "\n",
      "# Define prompt template\n",
      "prompt = PromptTemplate(\n",
      "    input_variables=[\"topic\"],\n",
      "    template=\"Explain {topic} in simple terms\"\n",
      ")\n",
      "\n",
      "# Create chain\n",
      "chain = prompt | llm\n",
      "result = chain.invoke({\"topic\": \"quantum computing\"})\n",
      "```\n",
      "\n",
      "Key Advantages:\n",
      "- Abstracts complex LLM interactions\n",
      "- Flexible and extensible\n",
      "- Supports complex AI workflows\n",
      "- Open-source and actively developed\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "parsed_chain_result = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "print(parsed_chain_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b860e",
   "metadata": {},
   "source": [
    "### Build a Retrieval Chain with LangChain and OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "085d8d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in ./pyenv/lib/python3.12/site-packages (4.13.4)\n",
      "Requirement already satisfied: langchain-openai in ./pyenv/lib/python3.12/site-packages (0.3.16)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./pyenv/lib/python3.12/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./pyenv/lib/python3.12/site-packages (from beautifulsoup4) (4.12.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in ./pyenv/lib/python3.12/site-packages (from langchain-openai) (0.3.58)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in ./pyenv/lib/python3.12/site-packages (from langchain-openai) (1.77.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./pyenv/lib/python3.12/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in ./pyenv/lib/python3.12/site-packages (from langchain_community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./pyenv/lib/python3.12/site-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in ./pyenv/lib/python3.12/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./pyenv/lib/python3.12/site-packages (from langchain_community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./pyenv/lib/python3.12/site-packages (from langchain_community) (9.0.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in ./pyenv/lib/python3.12/site-packages (from langchain_community) (0.3.42)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in ./pyenv/lib/python3.12/site-packages (from langchain_community) (2.2.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./pyenv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading multidict-6.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./pyenv/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.24->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./pyenv/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.24->langchain_community) (2.11.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./pyenv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./pyenv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (24.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./pyenv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./pyenv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./pyenv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./pyenv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./pyenv/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./pyenv/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./pyenv/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in ./pyenv/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./pyenv/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./pyenv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./pyenv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./pyenv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./pyenv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./pyenv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./pyenv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
      "Requirement already satisfied: greenlet>=1 in ./pyenv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./pyenv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in ./pyenv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./pyenv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./pyenv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./pyenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./pyenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain_community) (2.33.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.5/223.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (245 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.0/245.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (349 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.2/349.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain_community\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 dataclasses-json-0.6.7 frozenlist-1.6.0 httpx-sse-0.4.0 langchain_community-0.3.23 marshmallow-3.26.1 multidict-6.4.3 mypy-extensions-1.1.0 propcache-0.3.1 pydantic-settings-2.9.1 typing-inspect-0.9.0 yarl-1.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 langchain-openai langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a915380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "loader = WebBaseLoader(\"https://python.langchain.com/docs/how_to/\") # document used for question answering\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95d5763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28a1df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4af8f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "\n",
    "documsents = text_splitter.split_documents(docs)\n",
    "\n",
    "vector = FAISS.from_documents(documsents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6262e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the folliwng question based only on the provided context:\n",
    "                                          \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "                                          \n",
    "Question: {input}                                        \n",
    "\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17da40f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
      "  context: RunnableLambda(format_docs)\n",
      "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
      "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\nAswer the folliwng question based only on the provided context:\\n\\n<context>\\n{context}\\n</context>\\n\\nQuestion: {input}                                        \\n'), additional_kwargs={})])\n",
      "| ChatAnthropic(model='claude-3-5-haiku-latest', temperature=0.0, anthropic_api_url='https://api.anthropic.com', anthropic_api_key=SecretStr('**********'), model_kwargs={})\n",
      "| StrOutputParser() kwargs={} config={'run_name': 'stuff_documents_chain'} config_factories=[]\n"
     ]
    }
   ],
   "source": [
    "print(document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfff9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "response = retrieval_chain.invoke({\"input\": \"What is LangSmith?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "922da504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, LangSmith is a tool that allows you to closely trace, monitor, and evaluate your LLM (Large Language Model) application. It seamlessly integrates with LangChain and LangGraph, and enables you to inspect and debug individual steps of your chains and agents as you build them. \n",
      "\n",
      "The context highlights two key aspects of LangSmith:\n",
      "\n",
      "1. Evaluation: LangSmith helps with the entire process of evaluating LLM-powered applications, from creating a dataset to defining metrics to running evaluators.\n",
      "\n",
      "2. Tracing: Tracing provides observability inside your chains and agents, which is vital for diagnosing issues. LangSmith offers ways to trace with LangChain and add metadata and tags to traces.\n",
      "\n",
      "The documentation for LangSmith is hosted on a separate site, and users can find more detailed how-to guides there.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3edc3b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, LangSmith is a tool for development, monitoring, and testing.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "custom_resuilt = document_chain.invoke({\n",
    "    \"input\": \"What is LangSmith?\",\n",
    "    \"context\": [\n",
    "        Document(page_content=\"LangSmith is a tool for development, monitoring, and testing.\"),\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(custom_resuilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d400a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
